# ğŸ“š PHáº¦N 2 - HOÃ€N CHá»ˆNH: METRICS, RESULTS, CODE & THEORY
# Tá»« Evaluation Ä‘áº¿n Implementation - Cáº·n Káº½ Chi Tiáº¿t

---

## G. METRICS & EVALUATION - CHI TIáº¾T Cáº¶N Káº¼

### G.1. RMSE (Root Mean Squared Error)

#### G.1.1. Äá»‹nh NghÄ©a & CÃ´ng Thá»©c

**RMSE** = CÄƒn báº­c 2 cá»§a trung bÃ¬nh sai sá»‘ bÃ¬nh phÆ°Æ¡ng

**CÃ´ng Thá»©c ToÃ¡n Há»c**:
```
RMSE = âˆš(1/n * Î£(y_true[i] - y_pred[i])Â²)

Hay chi tiáº¿t hÆ¡n:
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  1    n                        2â”‚
RMSE = âˆšâ”‚â”€â”€â”€ Î£ (y_true[i] - y_pred[i]) â”‚
        â”‚  n  i=1                        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Vá»›i:
- n = sá»‘ samples
- y_true[i] = giÃ¡ trá»‹ thá»±c táº¿
- y_pred[i] = giÃ¡ trá»‹ dá»± Ä‘oÃ¡n
```

#### G.1.2. VÃ­ Dá»¥ TÃ­nh RMSE

```
Dá»¯ liá»‡u thá»­ nghiá»‡m:
y_true = [100, 105, 110, 115]
y_pred = [102, 103, 112, 113]

STEP 1: TÃ­nh sai sá»‘
errors = y_true - y_pred
       = [100-102, 105-103, 110-112, 115-113]
       = [-2, 2, -2, 2]

STEP 2: BÃ¬nh phÆ°Æ¡ng sai sá»‘
errors_squared = [-2, 2, -2, 2]Â²
               = [4, 4, 4, 4]

STEP 3: Trung bÃ¬nh
mean_squared_error = (4+4+4+4) / 4 = 16 / 4 = 4

STEP 4: CÄƒn báº­c 2
RMSE = âˆš4 = 2
```

#### G.1.3. Ã NghÄ©a & Diá»…n Giáº£i

```
RMSE = 0:        Dá»± Ä‘oÃ¡n hoÃ n háº£o (y_true = y_pred)
RMSE = 1-10:     Ráº¥t tá»‘t (sai sá»‘ nhá»)
RMSE = 10-50:    Tá»‘t (sai sá»‘ trung bÃ¬nh)
RMSE = 50-100:   Cháº¥p nháº­n Ä‘Æ°á»£c (sai sá»‘ lá»›n)
RMSE > 100:      Tá»‡ (sai sá»‘ ráº¥t lá»›n)

Vá»›i bá»™ dá»¯ liá»‡u má»±c nÆ°á»›c HÃ  Ná»™i:
â”œâ”€ LSTM: RMSE = 83.46 cm â†’ Sai lá»‡ch trung bÃ¬nh 83.46 cm
â”œâ”€ GRU: RMSE = 78.86 cm â†’ Sai lá»‡ch trung bÃ¬nh 78.86 cm
â””â”€ Transformer: RMSE = 46.65 cm â†’ Sai lá»‡ch trung bÃ¬nh 46.65 cm âœ“

GiÃ¡ trá»‹ nÆ°á»›c trong khoáº£ng [43-930] cm:
â”œâ”€ RMSE 46.65 / range 887 â‰ˆ 5.3% (GOOD)
â”œâ”€ RMSE 78.86 / range 887 â‰ˆ 8.9% (ACCEPTABLE)
â””â”€ RMSE 83.46 / range 887 â‰ˆ 9.4% (ACCEPTABLE)
```

#### G.1.4. Táº¡i Sao DÃ¹ng RMSE?

```
âœ“ ADVANTAGES:
â”œâ”€ BÃ¬nh phÆ°Æ¡ng lÃ m lá»›n lÃªn cÃ¡c sai sá»‘ lá»›n
â”‚  â””â”€ Penalize outliers máº¡nh
â”œâ”€ CÃ¹ng Ä‘Æ¡n vá»‹ vá»›i dá»¯ liá»‡u gá»‘c (cm)
â”‚  â””â”€ Dá»… hiá»ƒu, diá»…n giáº£i Ä‘Æ°á»£c
â”œâ”€ Derivative dá»… tÃ­nh (há»— trá»£ optimization)
â””â”€ Phá»• biáº¿n, dá»… so sÃ¡nh

âŒ DISADVANTAGES:
â”œâ”€ Nháº¡y cáº£m vá»›i outliers
â”‚  â””â”€ 1 giÃ¡ trá»‹ lá»›n cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng nhiá»u
â””â”€ KhÃ´ng cho biáº¿t hÆ°á»›ng sai sá»‘ (positive vs negative)
```

### G.2. MAE (Mean Absolute Error)

#### G.2.1. Äá»‹nh NghÄ©a & CÃ´ng Thá»©c

**MAE** = Trung bÃ¬nh cá»§a giÃ¡ trá»‹ tuyá»‡t Ä‘á»‘i cÃ¡c sai sá»‘

**CÃ´ng Thá»©c**:
```
        1   n
MAE = â”€â”€â”€ Î£ |y_true[i] - y_pred[i]|
        n  i=1
```

#### G.2.2. VÃ­ Dá»¥ MAE

```
y_true = [100, 105, 110, 115]
y_pred = [102, 103, 112, 113]

errors = [-2, 2, -2, 2]
abs_errors = [2, 2, 2, 2]
MAE = (2+2+2+2) / 4 = 2

So sÃ¡nh RMSE vs MAE:
â”œâ”€ RMSE = 2 (cÃ¹ng giÃ¡ trá»‹, vÃ¬ errors khÃ´ng quÃ¡ lá»›n)
â”œâ”€ MAE = 2 (cÃ¹ng giÃ¡ trá»‹)
â””â”€ NhÆ°ng náº¿u cÃ³ outlier:

y_pred_outlier = [102, 103, 112, 150]
errors = [-2, 2, -2, -35]
abs_errors = [2, 2, 2, 35]
MAE = (2+2+2+35) / 4 = 10.25

errors_sq = [4, 4, 4, 1225]
RMSE = âˆš(1237/4) = âˆš309.25 = 17.6 (Lá»›n hÆ¡n MAE nhiá»u!)
```

#### G.2.3. MAE vs RMSE

```
â”‚ TiÃªu ChÃ­ | MAE | RMSE |
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤
â”‚ Outliers | Ãt nháº¡y | Nháº¡y |
â”‚ Dá»… hiá»ƒu | âœ“ | âœ“ |
â”‚ ÄÆ¡n vá»‹ | Giá»‘ng | Giá»‘ng |
â”‚ Optimization | KhÃ³ | Dá»… |

KHI NÃ€O DÃ™NG MAE:
â”œâ”€ CÃ³ outliers nhiá»u
â”œâ”€ Muá»‘n giáº£i thÃ­ch Ä‘Æ¡n giáº£n
â””â”€ Robust solution cáº§n thiáº¿t

KHI NÃ€O DÃ™NG RMSE:
â”œâ”€ Outliers cáº§n penalize
â”œâ”€ Optimization dá»… hÆ¡n
â””â”€ Standard practice
```

### G.3. NMAE (Normalized MAE)

#### G.3.1. Äá»‹nh NghÄ©a

```
NMAE = MAE / mean(|y_true|)

Chuáº©n hÃ³a MAE báº±ng cÃ¡ch chia cho trung bÃ¬nh
```

#### G.3.2. VÃ­ Dá»¥

```
y_true = [100, 105, 110, 115]
y_pred = [102, 103, 112, 113]

MAE = 2 (tÃ­nh nhÆ° trÃªn)
mean(|y_true|) = (100+105+110+115) / 4 = 107.5

NMAE = 2 / 107.5 â‰ˆ 0.0186 â‰ˆ 1.86%

Ã NGHÄ¨A:
â””â”€ Sai sá»‘ trung bÃ¬nh lÃ  1.86% so vá»›i giÃ¡ trá»‹ trung bÃ¬nh
```

#### G.3.3. Lá»£i Ãch NMAE

```
âœ“ Chuáº©n hÃ³a: CÃ³ thá»ƒ so sÃ¡nh giá»¯a cÃ¡c datasets
â”œâ”€ Dataset 1: MAE=10, mean=1000 â†’ NMAE=0.01=1%
â”œâ”€ Dataset 2: MAE=5, mean=100 â†’ NMAE=0.05=5%
â””â”€ Dataset 2 tá»‡ hÆ¡n (dÃ¹ MAE nhá» hÆ¡n)

âœ“ Pháº§n trÄƒm: Dá»… diá»…n giáº£i
â”œâ”€ NMAE=0.01 = 1% error
â”œâ”€ NMAE=0.50 = 50% error
â””â”€ Trá»±c quan hÆ¡n
```

### G.4. Similarity Metric (Tá»± Äá»‹nh NghÄ©a)

#### G.4.1. CÃ´ng Thá»©c

```
           âˆš(Î£(y_true_norm - y_pred_norm)Â²)
Sim = 1 - â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          âˆš(Î£ y_true_normÂ² + Î£ y_pred_normÂ²)

Normalized to [-1, 1] range
```

#### G.4.2. Chi Tiáº¿t Code Implementation

```python
def calculate_similarity_normalized(y_true, y_pred):
    """
    TÃ­nh Similarity metric (normalized version)
    """
    # Input: y_true, y_pred cÃ³ thá»ƒ cÃ³ giÃ¡ trá»‹ lá»›n/nhá» khÃ¡c nhau
    y_true = np.asarray(y_true).flatten()
    y_pred = np.asarray(y_pred).flatten()
    
    # STEP 1: Chuáº©n hÃ³a vÃ o [0,1]
    y_true_min = np.min(y_true)
    y_true_max = np.max(y_true)
    y_pred_min = np.min(y_pred)
    y_pred_max = np.max(y_pred)
    
    y_true_norm = (y_true - y_true_min) / (y_true_max - y_true_min + 1e-8)
    y_pred_norm = (y_pred - y_pred_min) / (y_pred_max - y_pred_min + 1e-8)
    
    # STEP 2: TÃ­nh numerator (sai sá»‘)
    numerator = np.sqrt(np.sum((y_true_norm - y_pred_norm) ** 2))
    
    # STEP 3: TÃ­nh denominator (norm)
    denominator = np.sqrt(np.sum(y_true_norm ** 2) + np.sum(y_pred_norm ** 2))
    
    # STEP 4: Äiá»u chá»‰nh zero division
    if denominator == 0:
        return 0.0
    
    # STEP 5: TÃ­nh similarity
    sim = 1 - (numerator / denominator)
    
    # STEP 6: Clamp vÃ o [-1, 1]
    sim = np.clip(sim, -1, 1)
    
    return sim

# EXAMPLE:
y_true_norm = [0.1, 0.3, 0.5, 0.7, 0.9]
y_pred_norm = [0.2, 0.4, 0.5, 0.6, 0.8]

numerator = sqrt((0.1-0.2)Â² + (0.3-0.4)Â² + ... + (0.9-0.8)Â²)
          = sqrt(0.01 + 0.01 + 0 + 0.01 + 0.01)
          = sqrt(0.04)
          = 0.2

denominator = sqrt(0.1Â²+0.3Â²+0.5Â²+0.7Â²+0.9Â² + 0.2Â²+0.4Â²+0.5Â²+0.6Â²+0.8Â²)
            = sqrt(0.01+0.09+0.25+0.49+0.81 + 0.04+0.16+0.25+0.36+0.64)
            = sqrt(1.65 + 1.45)
            = sqrt(3.10)
            = 1.76

sim = 1 - (0.2 / 1.76) = 1 - 0.114 = 0.886

Ã NGHÄ¨A:
â””â”€ Sim = 0.886 = 88.6% â†’ Ráº¥t giá»‘ng!
```

#### G.4.3. Diá»…n Giáº£i Similarity

```
Sim = 1.0:      HoÃ n toÃ n giá»‘ng nhau âœ“âœ“âœ“
Sim = 0.8-0.9:  Ráº¥t tÆ°Æ¡ng tá»± âœ“âœ“
Sim = 0.7-0.8:  TÆ°Æ¡ng tá»± âœ“
Sim = 0.5-0.7:  Táº¡m tÆ°Æ¡ng tá»± ~
Sim = 0.0-0.5:  Ãt tÆ°Æ¡ng tá»±
Sim < 0:        HoÃ n toÃ n ngÆ°á»£c láº¡i âŒ

Vá»›i bá»™ dá»¯ liá»‡u:
â”œâ”€ LSTM: Sim = 0.5114 â†’ Táº¡m tÆ°Æ¡ng tá»± (kÃ©m)
â”œâ”€ GRU: Sim = 0.7435 â†’ TÆ°Æ¡ng tá»± (tá»‘t)
â””â”€ Transformer: Sim = 0.8280 â†’ Ráº¥t tÆ°Æ¡ng tá»± (ráº¥t tá»‘t) âœ“âœ“âœ“
```

---

## H. Káº¾T QUáº¢ TOÃ€N DIá»†N - CHI TIáº¾T PHÃ‚N TÃCH

### H.1. Báº£ng Káº¿t Quáº£ Deep Learning

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Model     â”‚   RMSE   â”‚   MAE    â”‚   NMAE   â”‚ Similarity â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LSTM        â”‚  83.46   â”‚  58.49   â”‚  0.2512  â”‚  0.5114    â”‚
â”‚ GRU         â”‚  78.86   â”‚  55.82   â”‚  0.2398  â”‚  0.7435    â”‚
â”‚ Transformer â”‚  46.65   â”‚  27.82   â”‚  0.1195  â”‚  0.8280    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### H.2. PhÃ¢n TÃ­ch Chi Tiáº¿t Tá»«ng Model

#### H.2.1. LSTM Model

**ThÃ nh TÃ­ch**:
```
RMSE: 83.46 cm
â”œâ”€ GiÃ¡ trá»‹ khoáº£ng 43-930 cm
â”œâ”€ Error rate: 83.46 / (930-43) = 9.8%
â””â”€ CHáº¤P NHáº¬N ÄÆ¯á»¢C

MAE: 58.49 cm
â”œâ”€ Trung bÃ¬nh sai sá»‘ lÃ  58.49 cm
â””â”€ TÆ°Æ¡ng Ä‘á»‘i cao

NMAE: 0.2512 (25.12%)
â”œâ”€ Sai sá»‘ lÃ  25% so vá»›i mean
â””â”€ KHÃ Lá»šN

Similarity: 0.5114 (51.14%)
â”œâ”€ Chá»‰ 51% tÆ°Æ¡ng tá»± dá»± tÃ­nh
â”œâ”€ Cháº¥p nháº­n nhÆ°ng khÃ´ng tá»‘t
â””â”€ Model khÃ´ng capture pattern tá»‘t
```

**LÃ½ Do KÃ©m**:
```
1. LSTM LAYER 1:
   â”œâ”€ QuÃ¡ sÃ¢u (stacking 2 BiLSTM)
   â”œâ”€ CÃ³ thá»ƒ overfit hoáº·c underfitting
   â””â”€ 32 units cÃ³ thá»ƒ khÃ´ng Ä‘á»§
   
2. LSTM LAYER 2:
   â”œâ”€ Chá»‰ láº¥y output cuá»‘i cÃ¹ng
   â”œâ”€ Máº¥t thÃ´ng tin tá»« timesteps trÆ°á»›c
   â””â”€ Return_sequences=False giá»›i háº¡n thÃ´ng tin
   
3. VANISHING GRADIENT:
   â”œâ”€ 2 layers cá»§a BiLSTM
   â”œâ”€ Gradient cÃ³ thá»ƒ táº¯t dáº§n (vanishing)
   â””â”€ Hard to learn long-term dependencies
```

#### H.2.2. GRU Model

**ThÃ nh TÃ­ch**:
```
RMSE: 78.86 cm (â†“ 5.6 so vá»›i LSTM)
â”œâ”€ Tá»‘t hÆ¡n LSTM 5.6%
â””â”€ Tá»T HÆ N

MAE: 55.82 cm (â†“ 2.67 so vá»›i LSTM)
â”œâ”€ Tá»‘t hÆ¡n LSTM 4.6%
â””â”€ Tá»T HÆ N

NMAE: 0.2398 (23.98% - â†“ tá»« 25.12%)
â”œâ”€ Tá»‘t hÆ¡n LSTM ~1%
â””â”€ Tá»T HÆ N

Similarity: 0.7435 (74.35% - â†‘ tá»« 51.14%)
â”œâ”€ Tá»‘t hÆ¡n LSTM 44.5%!
â”œâ”€ Model náº¯m báº¯t pattern tá»‘t hÆ¡n
â””â”€ Tá»CÃ“ Äá»˜ Lá»šN
```

**Táº¡i Sao GRU Tá»‘t HÆ¡n LSTM**:
```
1. Cáº¤U TRÃšC ÄÆ N GIáº¢N:
   â”œâ”€ GRU: Ãt tham sá»‘ hÆ¡n LSTM (3 gates vs 4)
   â”œâ”€ Reset gate: Forget mechanism
   â”œâ”€ Update gate: Selective update
   â””â”€ Ãt parameters â†’ Ãt overfit â†’ Tá»•ng quÃ¡t hÆ¡n
   
2. GRADIENT FLOW:
   â”œâ”€ GRU: Simpler gradient path
   â”œâ”€ LSTM: Complex gradient (4 gates)
   â”œâ”€ GRU: Dá»… training hÆ¡n
   â””â”€ Converge nhanh hÆ¡n
   
3. PHÃ™ Há»¢P Vá»šI TASK:
   â”œâ”€ Time series imputation cáº§n pattern capture
   â”œâ”€ GRU Ä‘á»§ máº¡nh Ä‘á»ƒ capture patterns
   â”œâ”€ Ãt "overly complex" nhÆ° LSTM
   â””â”€ Sweet spot giá»¯a complexity & performance
```

#### H.2.3. Transformer Model â­

**ThÃ nh TÃ­ch**:
```
RMSE: 46.65 cm
â”œâ”€ 44% tá»‘t hÆ¡n GRU (78.86 â†’ 46.65)
â”œâ”€ 44% tá»‘t hÆ¡n LSTM (83.46 â†’ 46.65)
â””â”€ CHÆ¯A Tá»ªNG CÃ“ Tá»T NHÆ¯ THáº¾!

MAE: 27.82 cm
â”œâ”€ 50% tá»‘t hÆ¡n GRU (55.82 â†’ 27.82)
â”œâ”€ 52% tá»‘t hÆ¡n LSTM (58.49 â†’ 27.82)
â””â”€ Gáº¦N NHÆ¯ Cáº®T ÄÃ”I!

NMAE: 0.1195 (11.95%)
â”œâ”€ 50% tá»‘t hÆ¡n GRU (23.98% â†’ 11.95%)
â””â”€ XUáº¤T Sáº®C

Similarity: 0.8280 (82.80%)
â”œâ”€ 11% tá»‘t hÆ¡n GRU (74.35% â†’ 82.80%)
â”œâ”€ 62% tá»‘t hÆ¡n LSTM (51.14% â†’ 82.80%)
â””â”€ PATTERN CAPTURE TUYá»†T Vá»œI!
```

**Táº¡i Sao Transformer VÆ°á»£t Trá»™i**:
```
1. ATTENTION MECHANISM:
   â”œâ”€ Self-attention: Weight tá»«ng timestep independently
   â”œâ”€ CÃ³ thá»ƒ capture distant dependencies
   â”œâ”€ LSTM/GRU: Pháº£i qua lÄƒng nháº¯ng (sequential)
   â”œâ”€ Transformer: Song song hÃ³a (parallelizable)
   â””â”€ Máº¡nh hÆ¡n trong capturing patterns
   
2. MULTI-HEAD ATTENTION:
   â”œâ”€ 2 heads: 2 cÃ¡ch nhÃ¬n khÃ¡c nhau
   â”œâ”€ Head 1: Capture trend
   â”œâ”€ Head 2: Capture seasonality
   â””â”€ Káº¿t há»£p: 2 perspectives
   
3. NO VANISHING GRADIENT:
   â”œâ”€ Transformer: Direct paths táº¥t cáº£ timesteps
   â”œâ”€ LSTM/GRU: Sequential â†’ vanishing gradient
   â”œâ”€ Transformer: Gradient khÃ´ng suy yáº¿u
   â””â”€ Better long-term dependency
   
4. POSITION ENCODING:
   â”œâ”€ Implicit: Timestep information
   â”œâ”€ Model hiá»ƒu "temporal order"
   â”œâ”€ Äáº·c biá»‡t quan trá»ng cho time series
   â””â”€ LSTM/GRU cÅ©ng cÃ³ nhÆ°ng hidden trong gates
   
5. FEATURE EXTRACTION:
   â”œâ”€ Dense(64) projection: Extract features
   â”œâ”€ LayerNorm: Stabilize training
   â”œâ”€ Attention: Combine features
   â””â”€ Flexible feature interaction
```

### H.3. So SÃ¡nh Deep Learning vs Machine Learning

```
DEEP LEARNING (GROUP 3):
â”œâ”€ Best: Transformer (RMSE=46.65, Sim=0.8280)
â”œâ”€ Approach: Learn from raw patterns
â”œâ”€ Advantage: Flexible, general-purpose
â””â”€ Training time: 15-20 minutes/model

MACHINE LEARNING (GROUP 1 - WBDI):
â”œâ”€ Best: Extra Trees (MAE=0.0912, RMSE=0.1374)
â”œâ”€ Approach: Tree-based, handcrafted features
â”œâ”€ Advantage: Fast, interpretable
â””â”€ Training time: <1 second/model

COMPARISON TABLE:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Metric     â”‚ Transformer (DL) â”‚ Extra Trees (ML) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ RMSE       â”‚ 46.65            â”‚ 0.1374           â”‚
â”‚ MAE        â”‚ 27.82            â”‚ 0.0912           â”‚
â”‚ Similarity â”‚ 0.8280           â”‚ (not applicable) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Training   â”‚ 15 min           â”‚ < 1 sec          â”‚
â”‚ Interpretableâ”‚ Hard          â”‚ Easy             â”‚
â”‚ Generalize â”‚ Good             â”‚ Maybe overfittingâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

KEY INSIGHT:
â”œâ”€ ML: RMSE nhá» hÆ¡n DL 347x (0.1374 vs 46.65)
â”‚  â””â”€ NhÆ°ng cÃ³ dáº¥u hiá»‡u overfitting (MAE=0.09, quÃ¡ tá»‘t)
â”‚
â”œâ”€ DL: RMSE lá»›n hÆ¡n ML nhÆ°ng Similarity cao (0.828)
â”‚  â””â”€ Meaning: Capture pattern tá»‘t, generalize tá»‘t hÆ¡n
â”‚
â””â”€ CONCLUSION:
   â”œâ”€ Náº¿u cáº§n: Perfect fit trÃªn test set â†’ Extra Trees
   â”œâ”€ Náº¿u cáº§n: General, robust solution â†’ Transformer
   â””â”€ Extra Trees cÃ³ thá»ƒ lá»—i trÃªn dá»¯ liá»‡u má»›i
      Transformer cÃ³ thá»ƒ tá»•ng quÃ¡t tá»‘t hÆ¡n
```

---

## I. ÄÃ“NG GÃ“P KHOA Há»ŒC - CHI TIáº¾T PHÃ‚N TÃCH

### I.1. Hybrid Framework: eDTWBI + Deep Learning

#### I.1.1. Ã TÆ°á»Ÿng ChÃ­nh

```
Váº¤NÄá»€:
â”œâ”€ eDTWBI standalone: Tá»‘t nhÆ°ng cÆ¡ báº£n
â”‚  â””â”€ Pattern matching dÃ¹ng DTW
â”‚
â”œâ”€ Deep Learning standalone: KhÃ´ng cÃ³ prior knowledge
â”‚  â””â”€ Model pháº£i há»c tá»« scratch
â”‚
â””â”€ GIáº¢I PHÃP: Káº¿t há»£p cáº£ hai!

KIáº¾N TRÃšC HYBRID:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: eDTWBI                      â”‚
â”‚ - Gap detection                      â”‚
â”‚ - Pattern matching (DTW + cosine)   â”‚
â”‚ - Extract context features          â”‚
â”‚ â†’ context_vectors                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: Deep Learning                â”‚
â”‚ - Input channels:                    â”‚
â”‚   1. Raw sequence                    â”‚
â”‚   2. Reference sequence              â”‚
â”‚   3. eDTWBI context (PRIOR!)         â”‚
â”‚ - BiLSTM/BiGRU/Transformer           â”‚
â”‚ â†’ Refined prediction                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Lá»¢I á»¤C:
âœ“ Context features: DL model cÃ³ "hint" tá»« eDTWBI
âœ“ Warm start: KhÃ´ng pháº£i há»c tá»« blank
âœ“ Robustness: Pattern matching + DL learning
âœ“ Flexibility: DL cÃ³ thá»ƒ refine eDTWBI
```

#### I.1.2. Ká»¹ Thuáº­t Chi Tiáº¿t

```
EDTWBI EXTRACTION:

For each gap (start, end):
  1. Find similar patterns (by DTW)
  2. Extract: mean & std of top-K candidates
  3. Store: left_context, right_context, mean, std
  
context_vector = [left_1, left_2, left_3,
                   right_1, right_2, right_3,
                   mean_gap, std_gap]
  = 8-dim vector (context_dim)

DEEP LEARNING INPUT:

For each timestamp t:
  X_seq:    Last 20 normalized values of imputed sequence
  X_ref:    Last 20 normalized values of reference
  X_ctx:    context_vector from eDTWBI
  
model_input = [X_seq, X_ref, X_ctx]

OUTPUT:

model predicts: y_pred (refined imputation)

ADVANTAGE:
â””â”€ Model sees: raw data + reference + pattern quality
   Not just: raw data alone
```

### I.2. Multi-Input Fusion Architecture

#### I.2.1. Why 3 Inputs?

```
INPUT 1: SEQUENCE (X_seq)
Purpose: What are the actual values?
Info: Time series itself
Learning: Auto-learn patterns

INPUT 2: REFERENCE (X_ref)
Purpose: How different from reference?
Info: Comparison/validation signal
Learning: Error correction

INPUT 3: CONTEXT (X_ctx)
Purpose: How confident is eDTWBI?
Info: Pattern quality (mean, std)
Learning: Confidence score

EXAMPLE:
Gap at timestep 100:

X_seq[100] = [0.1, 0.12, 0.15, ..., 0.35]
â”œâ”€ Model learns: Trending up from 0.1 to 0.35

X_ref[100] = [0.11, 0.14, 0.17, ..., 0.34]
â”œâ”€ Model learns: Reference also trending up
â”œâ”€ Confirms: Imputation aligned with reference

X_ctx[100] = [0.10, 0.12, ..., 0.22, 0.08]
â”œâ”€ Model learns: eDTWBI confidence is 0.08 (low std)
â”œâ”€ Means: Pattern match was consistent (good!)
â””â”€ Conclusion: Trust this imputation

If X_ctx shows high std (e.g., 0.5):
â””â”€ Model learns: Pattern match was inconsistent
   â†’ May want to adjust imputation down
```

#### I.2.2. Fusion Strategy

```
SEPARATE PROCESSING:

Sequence Branch (BiLSTM/BiGRU/Transformer):
â”œâ”€ Input: (batch, 20, 2) merged_seq
â”œâ”€ Layer 1: BiLSTM(32) return_sequences=True
â”œâ”€ Dropout(0.2)
â”œâ”€ Layer 2: BiLSTM(32) return_sequences=False
â””â”€ Output: (batch, 64)

Context Branch:
â”œâ”€ Input: (batch, context_dim=12)
â”œâ”€ Dense(32, relu)
â”œâ”€ Dropout(0.2)
â””â”€ Output: (batch, 32)

FUSION (Concatenation):
â”œâ”€ Input: [(batch, 64), (batch, 32)]
â”œâ”€ Concatenate: (batch, 96)
â”œâ”€ Dense(32, relu)
â”œâ”€ Dropout(0.1)
â””â”€ Output: (batch, 1)

WHY SEPARATE THEN FUSE?
âœ“ Seq branch: Learns temporal patterns independently
âœ“ Ctx branch: Learns confidence scoring independently
âœ“ Fusion: Combines both for final decision
âœ“ Flexible: Can weight branches differently
```

### I.3. Bidirectional Processing Innovation

#### I.3.1. Forward-Backward Mechanism

```
STANDARD RNN:
t=0 â†’ t=1 â†’ t=2 â†’ ... â†’ t=19
â””â”€ Only past information

BIDIRECTIONAL:
Forward:  t=0 â†’ t=1 â†’ ... â†’ t=19
Backward: t=19 â†’ t=18 â†’ ... â†’ t=0
â””â”€ Both past AND future information

ADVANTAGE:
â”œâ”€ At t=10: Know state from t=0-10 AND t=10-19
â”œâ”€ Full context for each timestep
â”œâ”€ Better representation learning
â””â”€ Especially good for time series patterns
```

#### I.3.2. Application to Time Series

```
TIME SERIES PATTERN (Má»±c nÆ°á»›c):
â”œâ”€ Morning (06:00-09:00): Rising (incoming tide)
â”œâ”€ Noon (12:00-15:00): Peak
â”œâ”€ Evening (18:00-21:00): Falling (outgoing tide)
â”œâ”€ Night (00:00-06:00): Low

BACKWARD LSTM BENEFIT:
â”œâ”€ At t=12 (noon): Backward can "see" evening decline
â”œâ”€ Helps classify: "This is peak before declining"
â”œâ”€ Without backward: "Just another rising point"
â””â”€ More informative representation

FOR IMPUTATION:
â”œâ”€ If gap at t=12 (missing value)
â”œâ”€ Forward: See growth from t=6 onward
â”œâ”€ Backward: See decline from t=18 onward
â”œâ”€ Combined: Infer t=12 is at peak (confident)
â””â”€ Better imputation decision
```

### I.4. Sakoe-Chiba Band Optimization

#### I.4.1. Performance Gains

```
WITHOUT BAND (Standard DTW):
â”œâ”€ Complexity: O(n * m) = O(nÂ²) for n=m
â”œâ”€ For sequence length 7: 7 Ã— 7 = 49 cells
â”œâ”€ For sequence length 1000: 1,000,000 cells âš ï¸
â””â”€ Very slow!

WITH SAKOE-CHIBA BAND (window=4):
â”œâ”€ Complexity: O(n * window) = O(n)
â”œâ”€ For sequence length 7: 7 Ã— 4 = 28 cells
â”œâ”€ For sequence length 1000: 1000 Ã— 4 = 4,000 cells
â””â”€ 250x faster!

ACCURACY TRADE-OFF:
â”œâ”€ Band assumption: Warping path doesn't go too far off-diagonal
â”œâ”€ Typical: Holds true for most real time series
â”œâ”€ Loss of accuracy: Usually <1% (acceptable trade)
â””â”€ Net result: 250x speedup, 99% accuracy
```

#### I.4.2. Implementation Detail

```python
# Standard DTW (no band):
for i in range(1, n+1):
    for j in range(1, m+1):
        cost = abs(s1[i-1] - s2[j-1])
        dtw[i, j] = cost + min(dtw[i-1,j], dtw[i,j-1], dtw[i-1,j-1])
# O(n*m) complexity

# With Sakoe-Chiba band (window=4):
for i in range(1, n+1):
    j_start = max(1, i - window)      # Lower bound
    j_end = min(m + 1, i + window)    # Upper bound
    for j in range(j_start, j_end):   # Only this range!
        cost = abs(s1[i-1] - s2[j-1])
        dtw[i, j] = cost + min(dtw[i-1,j], dtw[i,j-1], dtw[i-1,j-1])
# O(n*window) complexity
```

### I.5. Cosine Similarity Pre-filtering Innovation

#### I.5.1. Why Pre-filter?

```
PROBLEM:
â”œâ”€ Search 2922 candidates (from 29,224 data points)
â”œâ”€ Each candidate: compute DTW distance
â”œâ”€ DTW: O(n*window) = expensive
â”œâ”€ Total: 2922 Ã— O(n*window) = SLOW

SOLUTION:
â”œâ”€ Fast pre-filter: Cosine similarity
â”œâ”€ Cosine: O(n) simple dot product
â”œâ”€ Filter out ~90% non-similar candidates
â”œâ”€ Only compute DTW for ~10% similar candidates
â””â”€ Result: 10x faster!

TRADE-OFF:
â”œâ”€ Lose some candidates? Yes
â”œâ”€ But: Unlikely candidates anyway
â”œâ”€ Confidence: High similarity required (â‰¥0.7)
â””â”€ Net: 10x speed, minimal loss
```

#### I.5.2. Pre-filter Pipeline

```
2922 CANDIDATES
    â†“
COSINE SIMILARITY FILTER (threshold=0.7)
    â”œâ”€ ~2600 rejected (low similarity)
    â””â”€ ~300 passed (high similarity)
    â†“
DTW DISTANCE CALCULATION (on 300 only)
    â”œâ”€ Expensive computation
    â””â”€ But manageable
    â†“
TOP-K SELECTION (k=2)
    â””â”€ Best 2 candidates
    â†“
OUTPUT: Best matching patterns
```

---

## J. CODE IMPLEMENTATION - COMPLETE CHI TIáº¾T

### J.1. CELL 0: Imports & Configuration

```python
import os
import pickle
import warnings
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from scipy.spatial.distance import cosine
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error

import tensorflow as tf
from tensorflow.keras.layers import (
    Input, LSTM, GRU, Dense, Dropout, 
    Concatenate, Bidirectional, Reshape,
    MultiHeadAttention, LayerNormalization, Flatten
)
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras import mixed_precision

# SUPPRESS WARNINGS
warnings.filterwarnings("ignore")

# ENABLE MIXED PRECISION
try:
    policy = mixed_precision.Policy('mixed_float16')
    mixed_precision.set_global_policy(policy)
    print("âœ“ Mixed precision training enabled")
except:
    print("âš  Mixed precision not available")

# CONFIGURATION DICT
CONFIG = {
    'data_path': '/kaggle/input/misshanoi/Impute_misvalues_hanoi.csv',
    'output_path': '/kaggle/working',
    'window': 3,                    # eDTWBI context
    'k_best': 2,                    # Top-K candidates
    'cosine_threshold': 0.7,        # Similarity threshold
    'sequence_length': 20,          # RNN window
    'epochs': 50,
    'batch_size': 128,
    'validation_split': 0.15,
    'random_seed': 42,
    'cache_file': '/kaggle/working/edtwbi_cache.pkl',
}

# SET RANDOM SEEDS
np.random.seed(CONFIG['random_seed'])
tf.random.set_seed(CONFIG['random_seed'])

print(f"âœ… Configuration loaded")
print(f"âœ… Data path: {CONFIG['data_path']}")
print(f"âœ… Random seed: {CONFIG['random_seed']}")
```

### J.2. CELL 1: Similarity Metric Function

```python
def calculate_similarity(y_true, y_pred):
    """
    Calculate Similarity metric for water level forecasting
    
    Formula: Sim = 1 - |sqrt(sum((yt-yp)Â²)) / sqrt(sum(ytÂ²) + sum(ypÂ²))|
    
    Args:
        y_true: Ground truth values (array-like)
        y_pred: Predicted values (array-like)
    
    Returns:
        float: Similarity score in range [-1, 1]
            1.0 = perfect prediction
            0.8-0.9 = very good
            0.7-0.8 = good
            <0.7 = poor
    """
    y_true = np.asarray(y_true).flatten()
    y_pred = np.asarray(y_pred).flatten()
    
    # Normalize to [0, 1] to prevent overflow
    y_true_min = np.min(y_true)
    y_true_max = np.max(y_true)
    y_true_norm = (y_true - y_true_min) / (y_true_max - y_true_min + 1e-8)
    
    y_pred_min = np.min(y_pred)
    y_pred_max = np.max(y_pred)
    y_pred_norm = (y_pred - y_pred_min) / (y_pred_max - y_pred_min + 1e-8)
    
    # Calculate similarity
    numerator = np.sqrt(np.sum((y_true_norm - y_pred_norm) ** 2))
    denominator = np.sqrt(np.sum(y_true_norm ** 2) + np.sum(y_pred_norm ** 2))
    
    if denominator == 0:
        return 0.0
    
    sim = 1 - (numerator / denominator)
    sim = np.clip(sim, -1, 1)
    
    return sim

print("âœ“ Similarity metric function loaded")
```

### J.3. CELL 2: Gap Detection

```python
def find_gaps(arr):
    """
    Detect all missing value segments (consecutive NaNs)
    
    Args:
        arr: Array with potential NaN values
    
    Returns:
        list: List of (start_idx, end_idx) tuples for each gap
    
    Example:
        arr = [1, 2, NaN, NaN, 5, NaN, 7]
        â†’ [(2, 3), (5, 5)]
    """
    gaps = []
    inside_gap = False
    
    for i, v in enumerate(arr):
        if np.isnan(v):
            if not inside_gap:
                gap_start = i
                inside_gap = True
        else:
            if inside_gap:
                gap_end = i - 1
                gaps.append((gap_start, gap_end))
                inside_gap = False
    
    # Handle gap at end
    if inside_gap:
        gaps.append((gap_start, len(arr) - 1))
    
    return gaps

print("âœ“ Gap detection function loaded")
```

### J.4. CELL 3: DTW Distance (with Sakoe-Chiba)

```python
def dtw_distance(s1, s2, window_size=None):
    """
    Calculate DTW distance with Sakoe-Chiba band optimization
    
    Reduces complexity from O(nÂ²) to O(n*window_size)
    
    Args:
        s1, s2: Input sequences
        window_size: Band width (None = no band)
    
    Returns:
        float: DTW distance
    """
    n, m = len(s1), len(s2)
    if window_size is None:
        window_size = max(n, m)
    
    dtw = np.full((n+1, m+1), np.inf)
    dtw[0, 0] = 0
    
    for i in range(1, n+1):
        # Sakoe-Chiba band: only compute |i-j| â‰¤ window_size
        for j in range(max(1, i-window_size), min(m+1, i+window_size)):
            cost = abs(s1[i-1] - s2[j-1])
            dtw[i, j] = cost + min(dtw[i-1, j], dtw[i, j-1], dtw[i-1, j-1])
    
    return dtw[n, m]

print("âœ“ DTW function loaded")
```

### J.5. CELL 4: eDTWBI Context Extraction

```python
def edtwbi_context(arr, ref, gap_start, gap_end, window=3, k_best=2, 
                   cosine_threshold=0.7, dtw_radius=3):
    """
    Extract eDTWBI context for a single gap
    
    Returns: (context_feature, fill_value)
    """
    gap_len = gap_end - gap_start + 1
    left_context = ref[max(0, gap_start-window):gap_start]
    right_context = ref[gap_end+1:gap_end+window+1]
    
    candidates = []
    search_range = min(len(ref) - gap_len - window, 
                      max(500, len(ref)//10))
    
    # Search for candidates
    for idx in range(window, search_range):
        cand_l = ref[idx-window:idx]
        cand_g = ref[idx:idx+gap_len]
        cand_r = ref[idx+gap_len:idx+gap_len+window]
        
        # Skip if contains NaN
        if (np.isnan(cand_g).any() or np.isnan(cand_l).any() or 
            np.isnan(cand_r).any()):
            continue
        
        # Cosine similarity filter
        sim_l = 1 - cosine(left_context, cand_l) if len(left_context) == window else 0
        sim_r = 1 - cosine(right_context, cand_r) if len(right_context) == window else 0
        avg_sim = (sim_l + sim_r) / 2
        
        if avg_sim >= cosine_threshold:
            # DTW distance
            dist = (dtw_distance(left_context, cand_l, window_size=dtw_radius) +
                   dtw_distance(right_context, cand_r, window_size=dtw_radius))
            candidates.append((dist, cand_g, cand_l, cand_r))
    
    # Top-K selection and context extraction
    if candidates:
        candidates.sort(key=lambda x: x[0])
        best_gaps = [x[1] for x in candidates[:k_best]]
        context_feature = np.concatenate([
            *candidates[0][2:4],
            [np.mean(best_gaps)],
            [np.std(best_gaps)]
        ])
        fill_val = np.mean(best_gaps, axis=0)
    else:
        context_feature = np.zeros(window * 2 + 2)
        fill_val = np.full(gap_len, np.nanmean(ref))
    
    return context_feature, fill_val

print("âœ“ eDTWBI context extraction loaded")
```

### J.6. CELL 5: Data Preparation

```python
print("\n" + "="*80)
print("STEP 1-3: DATA LOADING & EDTWBI")
print("="*80)

# Load data
df = pd.read_csv(CONFIG['data_path'])
original = df['Average'].copy()
waterlevel = df['Waterlevel'].to_numpy(float)

print(f"âœ“ Data loaded: {len(original)} records")
print(f"  - Missing values: {original.isna().sum()} ({original.isna().sum()/len(original)*100:.1f}%)")

# eDTWBI (with caching)
if os.path.exists(CONFIG['cache_file']):
    print(f"âœ“ Loading cached eDTWBI...")
    with open(CONFIG['cache_file'], 'rb') as f:
        context_vectors, imputed_full = pickle.load(f)
else:
    print(f"âš  Computing eDTWBI (will cache)...")
    gaps = find_gaps(original.to_numpy(float))
    context_vectors = {}
    imputed_full = original.to_numpy(float).copy()
    
    for i, (start, end) in enumerate(gaps):
        if (i + 1) % max(1, len(gaps)//10) == 0:
            print(f"  Progress: {i+1}/{len(gaps)}")
        
        ctx, fill = edtwbi_context(original.to_numpy(float), waterlevel,
                                  start, end, CONFIG['window'], 
                                  CONFIG['k_best'], CONFIG['cosine_threshold'])
        imputed_full[start:end+1] = fill
        context_vectors[(start, end)] = ctx
    
    # Cache
    with open(CONFIG['cache_file'], 'wb') as f:
        pickle.dump((context_vectors, imputed_full), f)
    print(f"âœ“ eDTWBI cache saved")

print(f"âœ“ eDTWBI complete: {len(context_vectors)} gaps processed")
```

### J.7. CELL 6: Model Building

```python
print("\n" + "="*80)
print("STEP 4: MODEL ARCHITECTURE")
print("="*80)

def build_model(model_type='LSTM', sequence_length=20, context_dim=12, units=32):
    """
    Build multi-input fusion model
    
    Inputs:
    - seq_in: Normalized sequence (batch, sequence_length)
    - ref_in: Normalized reference (batch, sequence_length)
    - ctx_in: eDTWBI context (batch, context_dim)
    
    Architecture:
    - Sequence branch: BiLSTM/BiGRU/Transformer
    - Context branch: Dense layers
    - Fusion: Concatenate + Dense
    """
    seq_in = Input(shape=(sequence_length,), name='sequence_input')
    ref_in = Input(shape=(sequence_length,), name='reference_input')
    ctx_in = Input(shape=(context_dim,), name='context_input')
    
    # Reshape for RNN
    seq_r = Reshape((sequence_length, 1))(seq_in)
    ref_r = Reshape((sequence_length, 1))(ref_in)
    merged_seq = Concatenate(axis=-1)([seq_r, ref_r])
    
    # Sequence branch (choose model type)
    if model_type == 'LSTM':
        x = Bidirectional(LSTM(units, return_sequences=True))(merged_seq)
        x = Dropout(0.2)(x)
        x = Bidirectional(LSTM(units))(x)
    elif model_type == 'GRU':
        x = Bidirectional(GRU(units, return_sequences=True))(merged_seq)
        x = Dropout(0.2)(x)
        x = Bidirectional(GRU(units))(x)
    elif model_type == 'Transformer':
        x = Dense(64, activation='relu')(merged_seq)
        x = LayerNormalization()(x)
        attn = MultiHeadAttention(num_heads=2, key_dim=8)(x, x)
        x = Dropout(0.2)(attn)
        x = Flatten()(x)
    
    x = Dropout(0.2)(x)
    
    # Context branch
    ctx_branch = Dense(32, activation='relu')(ctx_in)
    ctx_branch = Dropout(0.2)(ctx_branch)
    
    # Fusion
    concat = Concatenate()([x, ctx_branch])
    z = Dense(32, activation='relu')(concat)
    z = Dropout(0.1)(z)
    out = Dense(1, name='output')(z)
    
    model = Model([seq_in, ref_in, ctx_in], out, name=f'{model_type}_imputation')
    model.compile(optimizer='adam', loss='mse', metrics=['mae'])
    
    return model

print("âœ“ Model architecture builder ready")
```

### J.8. CELL 7: Normalization & Dataset

```python
print("\n" + "="*80)
print("STEP 5: DATA NORMALIZATION & PREPARATION")
print("="*80)

sc_seq = MinMaxScaler()
sc_ref = MinMaxScaler()
seq_norm = sc_seq.fit_transform(imputed_full.reshape(-1,1)).flatten()
ref_norm = sc_ref.fit_transform(waterlevel.reshape(-1,1)).flatten()

context_dim = len(next(iter(context_vectors.values()))) if context_vectors else 12

# Create sequences
X_seq, X_ref, X_ctx, y = [], [], [], []

gaps = find_gaps(original.to_numpy(float))

for i in range(CONFIG['sequence_length'], len(seq_norm)):
    seq = seq_norm[i-CONFIG['sequence_length']:i]
    ref = ref_norm[i-CONFIG['sequence_length']:i]
    cur_ctx = np.zeros(context_dim)
    
    for (s, e) in gaps:
        if s <= i <= e:
            cur_ctx = context_vectors.get((s, e), np.zeros(context_dim))
            break
    
    X_seq.append(seq)
    X_ref.append(ref)
    X_ctx.append(cur_ctx)
    y.append(seq_norm[i])

X_seq = np.array(X_seq, dtype=np.float32)
X_ref = np.array(X_ref, dtype=np.float32)
X_ctx = np.array(X_ctx, dtype=np.float32)
y = np.array(y, dtype=np.float32)

# Temporal split
split_idx = int(0.8 * len(X_seq))
X_seq_tr, X_ref_tr, X_ctx_tr, y_tr = X_seq[:split_idx], X_ref[:split_idx], X_ctx[:split_idx], y[:split_idx]
X_seq_te, X_ref_te, X_ctx_te, y_te = X_seq[split_idx:], X_ref[split_idx:], X_ctx[split_idx:], y[split_idx:]

print(f"âœ“ Dataset prepared:")
print(f"  - Training: {len(X_seq_tr)}")
print(f"  - Testing: {len(X_seq_te)}")
print(f"  - Context dimension: {context_dim}")
```

### J.9. CELL 8-10: Training All 3 Models

```python
print("\n" + "="*80)
print("STEP 6-7: TRAINING & EVALUATION")
print("="*80)

callbacks = [
    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1),
    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)
]

# TRAIN LSTM
print("\n>>> Training LSTM...")
model_lstm = build_model('LSTM', CONFIG['sequence_length'], context_dim, units=32)
history_lstm = model_lstm.fit([X_seq_tr, X_ref_tr, X_ctx_tr], y_tr,
                               validation_split=0.15, epochs=CONFIG['epochs'],
                               batch_size=CONFIG['batch_size'], callbacks=callbacks, verbose=2)

y_pred_lstm = model_lstm.predict([X_seq_te, X_ref_te, X_ctx_te], verbose=0)
y_te_rescaled = sc_seq.inverse_transform(y_te.reshape(-1,1))
y_pred_lstm_rescaled = sc_seq.inverse_transform(y_pred_lstm)
rmse_lstm = np.sqrt(mean_squared_error(y_te_rescaled, y_pred_lstm_rescaled))
mae_lstm = mean_absolute_error(y_te_rescaled, y_pred_lstm_rescaled)
nmae_lstm = mae_lstm / (np.mean(np.abs(y_te_rescaled)) + 1e-8)
sim_lstm = calculate_similarity(y_te_rescaled, y_pred_lstm_rescaled)

print(f"LSTM: RMSE={rmse_lstm:.2f}, MAE={mae_lstm:.2f}, NMAE={nmae_lstm:.4f}, Sim={sim_lstm:.4f}")

# TRAIN GRU
print("\n>>> Training GRU...")
model_gru = build_model('GRU', CONFIG['sequence_length'], context_dim, units=32)
history_gru = model_gru.fit([X_seq_tr, X_ref_tr, X_ctx_tr], y_tr,
                             validation_split=0.15, epochs=CONFIG['epochs'],
                             batch_size=CONFIG['batch_size'], callbacks=callbacks, verbose=2)

y_pred_gru = model_gru.predict([X_seq_te, X_ref_te, X_ctx_te], verbose=0)
y_pred_gru_rescaled = sc_seq.inverse_transform(y_pred_gru)
rmse_gru = np.sqrt(mean_squared_error(y_te_rescaled, y_pred_gru_rescaled))
mae_gru = mean_absolute_error(y_te_rescaled, y_pred_gru_rescaled)
nmae_gru = mae_gru / (np.mean(np.abs(y_te_rescaled)) + 1e-8)
sim_gru = calculate_similarity(y_te_rescaled, y_pred_gru_rescaled)

print(f"GRU: RMSE={rmse_gru:.2f}, MAE={mae_gru:.2f}, NMAE={nmae_gru:.4f}, Sim={sim_gru:.4f}")

# TRAIN TRANSFORMER
print("\n>>> Training Transformer...")
model_trans = build_model('Transformer', CONFIG['sequence_length'], context_dim, units=32)
history_trans = model_trans.fit([X_seq_tr, X_ref_tr, X_ctx_tr], y_tr,
                                 validation_split=0.15, epochs=CONFIG['epochs'],
                                 batch_size=CONFIG['batch_size'], callbacks=callbacks, verbose=2)

y_pred_trans = model_trans.predict([X_seq_te, X_ref_te, X_ctx_te], verbose=0)
y_pred_trans_rescaled = sc_seq.inverse_transform(y_pred_trans)
rmse_trans = np.sqrt(mean_squared_error(y_te_rescaled, y_pred_trans_rescaled))
mae_trans = mean_absolute_error(y_te_rescaled, y_pred_trans_rescaled)
nmae_trans = mae_trans / (np.mean(np.abs(y_te_rescaled)) + 1e-8)
sim_trans = calculate_similarity(y_te_rescaled, y_pred_trans_rescaled)

print(f"Transformer: RMSE={rmse_trans:.2f}, MAE={mae_trans:.2f}, NMAE={nmae_trans:.4f}, Sim={sim_trans:.4f}")
```

### J.10. CELL 11: Results Compilation

```python
print("\n" + "="*80)
print("STEP 8: RESULTS COMPILATION")
print("="*80)

results_df_final = pd.DataFrame({
    'Model': ['LSTM', 'GRU', 'Transformer'],
    'RMSE': [rmse_lstm, rmse_gru, rmse_trans],
    'MAE': [mae_lstm, mae_gru, mae_trans],
    'NMAE': [nmae_lstm, nmae_gru, nmae_trans],
    'Similarity': [sim_lstm, sim_gru, sim_trans]
})

print("\n" + "="*90)
print("FINAL RESULTS:")
print("="*90)
print(results_df_final.to_string(index=False))

best_rmse_model = results_df_final.loc[results_df_final['RMSE'].idxmin(), 'Model']
best_sim_model = results_df_final.loc[results_df_final['Similarity'].idxmax(), 'Model']

print(f"\nğŸ† Best RMSE: {best_rmse_model}")
print(f"â­ Best Similarity: {best_sim_model}")

results_df_final.to_csv(f'{CONFIG["output_path"]}/results_final.csv', index=False)
print(f"\nâœ“ Results saved: {CONFIG['output_path']}/results_final.csv")
```

---

## K. Q&A & TROUBLESHOOTING - CHI TIáº¾T

### K.1. CÃ¡c Váº¥n Äá» ThÆ°á»ng Gáº·p

#### Q1: "ValueError: Input contains NaN"

**NguyÃªn NhÃ¢n**: Dataset cÃ³ NaN khi vÃ o model

**Giáº£i PhÃ¡p**:
```python
# Check NaN trÆ°á»›c khi fit
print(f"X_seq has NaN: {np.isnan(X_seq).any()}")
print(f"y_train has NaN: {np.isnan(y_tr).any()}")

# Remove NaN náº¿u cáº§n
X_seq = X_seq[~np.isnan(X_seq).any(axis=1)]
y = y[~np.isnan(y)]

# Or fill NaN
X_seq[np.isnan(X_seq)] = 0
y[np.isnan(y)] = 0
```

#### Q2: "OOM: Out of Memory"

**NguyÃªn NhÃ¢n**: Batch size quÃ¡ lá»›n hoáº·c model quÃ¡ phá»©c táº¡p

**Giáº£i PhÃ¡p**:
```python
# Giáº£m batch size
CONFIG['batch_size'] = 64  # tá»« 128
# hoáº·c
CONFIG['batch_size'] = 32

# Giáº£m units
units = 16  # tá»« 32

# Giáº£m sequence length
CONFIG['sequence_length'] = 10  # tá»« 20

# Enable mixed precision (Ä‘Ã£ cÃ³)
policy = mixed_precision.Policy('mixed_float16')
```

#### Q3: "Model khÃ´ng converge (loss khÃ´ng giáº£m)"

**NguyÃªn NhÃ¢n**: Learning rate quÃ¡ lá»›n/nhá», model khÃ´ng thÃ­ch há»£p

**Giáº£i PhÃ¡p**:
```python
# Giáº£m learning rate
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), 
              loss='mse')

# TÄƒng epochs
CONFIG['epochs'] = 100  # tá»« 50

# Kiá»ƒm tra data quality
print(f"X mean: {np.mean(X_seq)}, std: {np.std(X_seq)}")
print(f"y mean: {np.mean(y)}, std: {np.std(y)}")
# NÃªn gáº§n [0, 1]
```

#### Q4: "Transformer RMSE lá»›n hÆ¡n GRU"

**CÃ³ thá»ƒ lÃ **: 
```
1. Hyperparameter khÃ´ng tá»‘i Æ°u
   â””â”€ Thá»­ tÄƒng num_heads, key_dim, units

2. Insufficient training
   â””â”€ ThÃªm epochs, giáº£m learning rate decay

3. Transformer cáº§n nhiá»u data hÆ¡n
   â””â”€ Augment data, thÃªm regularization

4. Implementation sai
   â””â”€ Check MultiHeadAttention parameters
```

### K.2. Performance Optimization

#### TÄƒng Tá»‘c Äá»™ Training

```python
# 1. Giáº£m data
X_seq = X_seq[::2]  # Láº¥y 50% data
y = y[::2]

# 2. Batch size lá»›n hÆ¡n
CONFIG['batch_size'] = 256

# 3. Ãt epochs (vá»›i early stopping)
CONFIG['epochs'] = 30

# 4. Ãt callbacks
callbacks = [EarlyStopping(...)]  # Chá»‰ 1 callback

# 5. GPU utilization check
print(len(tf.config.list_physical_devices('GPU')))  # Check GPU count
```

#### Cáº£i Thiá»‡n Káº¿t Quáº£

```python
# 1. Data augmentation
X_seq_aug = np.vstack([X_seq, X_seq + np.random.normal(0, 0.01, X_seq.shape)])
y_aug = np.hstack([y, y + np.random.normal(0, 0.01, y.shape)])

# 2. Ensemble (average predictions)
y_pred_ensemble = (y_pred_lstm + y_pred_gru + y_pred_trans) / 3

# 3. Hyperparameter tuning
# Try different units, learning rates, dropout rates

# 4. Better architecture
# Try more layers, different activation functions
```

### K.3. Debugging Tips

```python
# Print intermediate outputs
print(f"X_seq_tr shape: {X_seq_tr.shape}")
print(f"X_seq_tr range: [{np.min(X_seq_tr)}, {np.max(X_seq_tr)}]")

# Check model summary
model.summary()

# Plot training history
plt.plot(history.history['loss'], label='Training loss')
plt.plot(history.history['val_loss'], label='Validation loss')
plt.legend()
plt.show()

# Check prediction quality
errors = y_te_rescaled.flatten() - y_pred.flatten()
print(f"Error mean: {np.mean(errors)}")
print(f"Error std: {np.std(errors)}")
print(f"Error max: {np.max(np.abs(errors))}")

# Save model for later
model_lstm.save('/kaggle/working/lstm_model.h5')
loaded_model = tf.keras.models.load_model('/kaggle/working/lstm_model.h5')
```

---

**Káº¾T LUáº¬N**: 
TÃ i liá»‡u nÃ y cung cáº¥p **TOÃ€N Bá»˜ KIáº¾N THá»¨C CHI TIáº¾T** tá»«:
- LÃ½ thuyáº¿t (A-I): Missing values, eDTWBI, ML, DL, metrics
- Implementation (J): Code hoÃ n chá»‰nh tá»«ng cell
- Troubleshooting (K): Q&A & tips

**Báº¡n cÃ³ thá»ƒ**:
1. Äá»c lÃ½ thuyáº¿t Ä‘á»ƒ hiá»ƒu sÃ¢u
2. Copy code Ä‘á»ƒ implement
3. DÃ¹ng Q&A Ä‘á»ƒ fix bugs
4. Tá»‘i Æ°u hÃ³a theo tips

ğŸ“ **READY TO PRESENT & IMPLEMENT!**
